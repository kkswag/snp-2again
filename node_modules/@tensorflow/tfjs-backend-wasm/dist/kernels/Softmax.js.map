{"version":3,"file":"Softmax.js","sourceRoot":"","sources":["../../src/kernels/Softmax.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AAEH,OAAO,EAA2B,OAAO,EAA2C,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAIvH,IAAI,QACI,CAAC;AAET,SAAS,KAAK,CAAC,OAAoB;IACjC,QAAQ,GAAG,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,EAAE;QACtD,QAAQ;QACR,QAAQ;QACR,QAAQ;QACR,QAAQ,CAAG,QAAQ;KACpB,CAAC,CAAC;AACL,CAAC;AAED,SAAS,OAAO,CACZ,IAAwE;IAE1E,MAAM,EAAC,OAAO,EAAE,MAAM,EAAE,EAAC,MAAM,EAAC,EAAE,KAAK,EAAE,EAAC,GAAG,EAAC,EAAC,GAAG,IAAI,CAAC;IACvD,MAAM,GAAG,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,EAAE,CAAC;IACpD,MAAM,GAAG,GAAG,OAAO,CAAC,UAAU,CAAC,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC;IAC3D,MAAM,KAAK,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,CAAC;IAEnD,MAAM,QAAQ,GAAG,MAAM,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IACnC,MAAM,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,QAAQ,CAAC;IAE1D,oCAAoC;IACpC,IAAI,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE;QACvC,OAAO,GAAG,CAAC;KACZ;IAED,QAAQ,CAAC,GAAG,EAAE,KAAK,EAAE,QAAQ,EAAE,KAAK,CAAC,CAAC;IACtC,OAAO,GAAG,CAAC;AACb,CAAC;AAED,MAAM,CAAC,MAAM,aAAa,GAAiB;IACzC,UAAU,EAAE,OAAO;IACnB,WAAW,EAAE,MAAM;IACnB,SAAS,EAAE,KAAK;IAChB,UAAU,EAAE,OAA2B;CACxC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmFunc: (xId: number, outId: number, channels: number, batch: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(Softmax, null /* void */, [\n    'number',  // xId\n    'number',  // outId\n    'number',  // channels\n    'number'   // batch\n  ]);\n}\n\nfunction softmax(\n    args: {backend: BackendWasm, inputs: SoftmaxInputs, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {backend, inputs: {logits}, attrs: {dim}} = args;\n  const xId = backend.dataIdMap.get(logits.dataId).id;\n  const out = backend.makeOutput(logits.shape, logits.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const channels = logits.shape[dim];\n  const batch = util.sizeFromShape(logits.shape) / channels;\n\n  // Short-circuit zero-sized tensors.\n  if (util.sizeFromShape(out.shape) === 0) {\n    return out;\n  }\n\n  wasmFunc(xId, outId, channels, batch);\n  return out;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: softmax as {} as KernelFunc\n};\n"]}